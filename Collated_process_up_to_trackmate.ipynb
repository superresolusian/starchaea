{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is an example of how to perform the following tasks:\n",
    "* Read one- and two-channel timelapse images into the notebook\n",
    "* Create a file saving structure for notebook outputs\n",
    "* Registration of timelapse data to compensate for drift\n",
    "* Run Stardist 2D models on the data to perform segmentations in both channels\n",
    "\n",
    "<font color=red>Example images for running this notebook are available at.........</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python imports\n",
    "The cell below deals with importing necessary packages and dependencies for running the notebook. You don't need to worry about what it does, it just needs to be run :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, unicode_literals, absolute_import, division\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from glob import glob\n",
    "from tqdm.notebook import tqdm\n",
    "from tifffile import imread, TiffFile\n",
    "from csbdeep.utils import Path, normalize\n",
    "from csbdeep.io import save_tiff_imagej_compatible\n",
    "\n",
    "import imreg_dft as ird\n",
    "\n",
    "from stardist import export_imagej_rois\n",
    "from stardist.models import StarDist2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File information\n",
    "The below cell tells the code where to find the file(s) to analyse, and also any preferences you have for the analysis.\n",
    "\n",
    "### File location\n",
    "`raw_file_path` is the path where the data that you will be analysing is currently stored. On a Mac, this will normally look something like `'Users/sculley/Desktop/NR_DNA_imm/raw data'`. On Windows, it will look something like `r'D:\\200311 - New Sulfoscope data\\NR_DNA_imm\\raw data'`. Note the difference in the slash directions, and also the rogue 'r' at the beginning of the Windows path.\n",
    "\n",
    "Important! This code assumes that you have saved your images in multi-image .tif format, for example the stacks and hyperstacks that you can save from ImageJ/Fiji.\n",
    "\n",
    "### Analysis options: channels\n",
    "`do_two_colour` determines whether you want to do Stardist segmentation of both channels of a two-colour image. If you do, then you should set this variable to `True`. Otherwise, set it to `False`. If your data only has one channel, then you don't need to worry about what this variable is set to!\n",
    "\n",
    "`single_channel_to_segment` allows you to specify which channel you want to segment, if your data contains >1 channel and you don't want to segment both channels. Set this value to `1` if you want to analyse the first channel, and `2` if you want to analyse the second channel. Jf your data only has one channel, set this value to `1`. The value doesn't matter or if you are analysing both channels of a two-colour dataset :-)\n",
    "\n",
    "### Analysis options: drift correction\n",
    "`do_drift_correction` lets you choose if you want to drift correct your data. If you do want to enable drift correction, set this to `True`, otherwise set it to `False`.\n",
    "\n",
    "`reference_channel_for_drift_correction` lets you specify the channel to perform drift correction on (for a two-channel dataset). It will then apply the same drift correction to the other channel. Again, set this to `1` to use the first channel, `2` to use the second channel etc. Don't worry about this value if your data only has one channel!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_file_path = r'.\\data\\two-colour data\\raw data'\n",
    "\n",
    "do_two_colour = True\n",
    "single_channel_to_segment = 1\n",
    "\n",
    "do_drift_correction = False\n",
    "reference_channel_for_drift_correction = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create file saving structure\n",
    "The below cell finds the images in the folder you specified in `raw_file_path`. It then creates save directories in the parent folder of `raw_file_path` for the Stardist segmentation results and drift-corrected images, if you wanted to do drift-correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base folder is data\\two-colour data\n",
      "There are 2 datasets to analyse :-)\n",
      "Successfully created save directories, yay!\n"
     ]
    }
   ],
   "source": [
    "raw_files = sorted(Path(raw_file_path).rglob('*.tif'))\n",
    "base_dir = raw_files[0].parent.parent\n",
    "print(f'Base folder is {base_dir}')\n",
    "\n",
    "n_raw_files = len(raw_files)\n",
    "print(f'There are {n_raw_files} datasets to analyse :-)')\n",
    "      \n",
    "if do_drift_correction:\n",
    "    registered_dir = base_dir/f'registered data'\n",
    "    registered_dir.mkdir(exist_ok=True)\n",
    "\n",
    "stardist_dir = base_dir/f'stardist results'\n",
    "stardist_dir.mkdir(exist_ok=True)\n",
    "if do_two_colour:\n",
    "    stardist_1_dir = stardist_dir/f'channel 1'\n",
    "    stardist_2_dir = stardist_dir/f'channel 2'\n",
    "    stardist_1_dir.mkdir(exist_ok=True)\n",
    "    stardist_2_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print('Successfully created save directories, yay!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Stardist model(s)\n",
    "We need to tell the code where to find the Stardist models. You should keep your models in their own folder, called something intuitive like, well, 'models'. Point the `model_dir` variable to where this folder is, in the same way that you did for `raw_file_path` earlier.\n",
    "\n",
    "You also want to tell the code which models to use for which channels. You do this by changing the variable names `channel_1_model_name` and `channel_2_model_name`. If you're only doing one channel, then set `channel_2_model_name` to `None`, for example: `channel_2_model_name = None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = 'models'\n",
    "channel_1_model_name = 'stardist-2020-elastic'\n",
    "channel_2_model_name = 'stardist_dna_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\python366\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\python366\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\python366\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\python366\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\python366\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2239: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "Loading network weights from 'weights_now.h5'.\n",
      "WARNING:tensorflow:From c:\\python366\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\python366\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\python366\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\python366\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\python366\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\python366\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "Loading thresholds from 'thresholds.json'.\n",
      "Using default values: prob_thresh=0.844602, nms_thresh=0.3.\n",
      "Loading network weights from 'weights_best.h5'.\n",
      "Loading thresholds from 'thresholds.json'.\n",
      "Using default values: prob_thresh=0.696284, nms_thresh=0.3.\n"
     ]
    }
   ],
   "source": [
    "if do_two_colour:\n",
    "    model_1 = StarDist2D(None, name=channel_1_model_name, basedir=model_dir)\n",
    "    model_2 = StarDist2D(None, name=channel_2_model_name, basedir=model_dir)\n",
    "else:\n",
    "    if single_channel_to_segment==1:\n",
    "        model = StarDist2D(None, name=channel_1_model_name, basedir=model_dir)\n",
    "    else:\n",
    "        model = StarDist2D(None, name=channel_2_model_name, basedir=model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Stardist thresholds\n",
    "There are two thresholds in Stardist that determine the segmentation results:\n",
    "* `prob_thresh`\n",
    "* `nms_thresh`\n",
    "\n",
    "<font color=red>Uwe/Martin to write something about thresholds, maybe about using `model.export_TF()` to check in Fiji</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_thresh_1 = None\n",
    "nms_thresh_1 = 0.7\n",
    "\n",
    "prob_thresh_2 = None\n",
    "nms_thresh_2 = 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define drift correction functions\n",
    "The below functions define the drift correction. You don't need to worry about them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(file):\n",
    "    print(f'Loading image from {file}')\n",
    "    T = imread(str(file))\n",
    "    \n",
    "    if T.ndim==3:\n",
    "        axes = 'TYX'\n",
    "    elif T.ndim==4:\n",
    "        axes = 'TCYX'\n",
    "    else:\n",
    "        raise ValueError('Image shape has incorrect number of dimensions')\n",
    "    \n",
    "    print(f'Data has axes {axes} with shape {T.shape}')\n",
    "    \n",
    "    return T, axes\n",
    "\n",
    "def register(T, reg_ch):\n",
    "    \n",
    "    if T.ndim==3:\n",
    "        reg_ch = None\n",
    "    \n",
    "    def _reg(x):\n",
    "        return x if reg_ch is None else x[reg_ch]\n",
    "    \n",
    "    R = [T[0]]\n",
    "    \n",
    "    print(f'Running drift correction...')\n",
    "    \n",
    "    for frame in tqdm(T[1:]):\n",
    "        result = ird.translation(_reg(R[-1]), _reg(frame))\n",
    "        if reg_ch is None:\n",
    "            freg = ird.transform_img(frame, tvec=result[\"tvec\"])\n",
    "        else:\n",
    "            freg = np.stack([ird.transform_img(c, tvec=result[\"tvec\"]) for c in frame])\n",
    "        R.append(freg)\n",
    "    \n",
    "    reg = np.stack(R)\n",
    "    \n",
    "    return reg\n",
    "\n",
    "def do_registration(T, axes, reg_ch):\n",
    "\n",
    "    T_reg = register(T, reg_ch)\n",
    "    T_reg = T_reg.astype(T.dtype)\n",
    "    \n",
    "    reg_file = registered_dir / (r'DRIFTCORRECTED_' + file.name)\n",
    "    \n",
    "    with TiffFile(str(file)) as _file:\n",
    "        imagej_metadata = _file.imagej_metadata\n",
    "        ome_metadata = _file.ome_metadata\n",
    "        \n",
    "    save_tiff_imagej_compatible(str(reg_file), T_reg, axes=axes, metadata=imagej_metadata)\n",
    "    \n",
    "    return T_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define StarDist functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_stardist_prediction(model, T, channel, axes, prob_thresh, nms_thresh, out_dir):\n",
    "    \n",
    "    if T.ndim==3:\n",
    "        timelapse = T\n",
    "    elif T.ndim==4:\n",
    "        timelapse = T[:,channel]\n",
    "    else:\n",
    "        raise ValueError('Data has unexpected number of dimensions. Weird.')\n",
    "        \n",
    "    # normalise\n",
    "    print(f'Normalizing each frame to run Stardist', flush=True)\n",
    "    timelapse = np.stack([normalize(frame, 1,99.8) for frame in timelapse])\n",
    "    print(f\"Timelapse has axes {axes.replace('C','')} with shape {timelapse.shape}\")\n",
    "\n",
    "    polygons = [model.predict_instances(frame, nms_thresh=nms_thresh, prob_thresh=prob_thresh)[1] for frame in tqdm(timelapse)]\n",
    "\n",
    "    if prob_thresh is None:\n",
    "        prob_string = 'default'\n",
    "    else:\n",
    "        prob_string = f'{prob_thresh:.2f}'\n",
    "        \n",
    "    if nms_thresh is None:\n",
    "        nms_string  = 'default'\n",
    "    else:\n",
    "        nms_string = f'{nms_thresh:.2f}'\n",
    "    \n",
    "    roi_path = out_dir / f\"{file.stem}_prob={prob_string}_nms={nms_string}\"\n",
    "    roi_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    rois_python = Path(str(roi_path)+'.npz')\n",
    "    rois_imagej = Path(str(roi_path)+'.zip')\n",
    "    \n",
    "    print(f'Saving ImageJ ROIs to {rois_imagej}')\n",
    "    export_imagej_rois(str(rois_imagej), [poly['coord'] for poly in polygons])\n",
    "          \n",
    "    print(f'Saving Python rois to {rois_python}')\n",
    "    np.savez(str(rois_python),\n",
    "        coord  = [p['coord']  for p in polygons],\n",
    "        points = [p['points'] for p in polygons],\n",
    "        prob   = [p['prob']   for p in polygons],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run analysis\n",
    "The below cell is the main loop to run the analysis. It will loop through each dataset in the raw data directory, do registration if required, and then run Stardist to perform segmentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading image from data\\two-colour data\\raw data\\membrane_dna_1.tif\n",
      "Data has axes TCYX with shape (64, 2, 600, 600)\n",
      "~~ Running predictions on channel 1 ~~\n",
      "Normalizing each frame to run Stardist\n",
      "Timelapse has axes TYX with shape (64, 600, 600)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0695141bf3c64375af77732a9e2b7cc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=64.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving ImageJ ROIs to data\\two-colour data\\stardist results\\channel 1\\membrane_dna_1_prob=default_nms=0.70.zip\n",
      "Saving Python rois to data\\two-colour data\\stardist results\\channel 1\\membrane_dna_1_prob=default_nms=0.70.npz\n",
      "~~ Running predictions on channel 2 ~~\n",
      "Normalizing each frame to run Stardist\n",
      "Timelapse has axes TYX with shape (64, 600, 600)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ca8c41d90bb4641b4b412060d4b997c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=64.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving ImageJ ROIs to data\\two-colour data\\stardist results\\channel 2\\membrane_dna_1_prob=default_nms=0.70.zip\n",
      "Saving Python rois to data\\two-colour data\\stardist results\\channel 2\\membrane_dna_1_prob=default_nms=0.70.npz\n",
      "Loading image from data\\two-colour data\\raw data\\membrane_dna_2.tif\n",
      "Data has axes TCYX with shape (69, 2, 600, 600)\n",
      "~~ Running predictions on channel 1 ~~\n",
      "Normalizing each frame to run Stardist\n",
      "Timelapse has axes TYX with shape (69, 600, 600)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f06fd6f6be6e42b7b10c88a40895ca8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=69.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving ImageJ ROIs to data\\two-colour data\\stardist results\\channel 1\\membrane_dna_2_prob=default_nms=0.70.zip\n",
      "Saving Python rois to data\\two-colour data\\stardist results\\channel 1\\membrane_dna_2_prob=default_nms=0.70.npz\n",
      "~~ Running predictions on channel 2 ~~\n",
      "Normalizing each frame to run Stardist\n",
      "Timelapse has axes TYX with shape (69, 600, 600)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a70901be78d4c95863c8f489bcde050",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=69.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving ImageJ ROIs to data\\two-colour data\\stardist results\\channel 2\\membrane_dna_2_prob=default_nms=0.70.zip\n",
      "Saving Python rois to data\\two-colour data\\stardist results\\channel 2\\membrane_dna_2_prob=default_nms=0.70.npz\n"
     ]
    }
   ],
   "source": [
    "for file in raw_files:\n",
    "    T, axes = pre_process(file)\n",
    "    \n",
    "    if do_drift_correction:\n",
    "        T = do_registration(T, axes, reference_channel_for_drift_correction-1)\n",
    "    \n",
    "    if do_two_colour:\n",
    "        print('~~ Running predictions on channel 1 ~~')\n",
    "        do_stardist_prediction(model_1, T, 0, axes, prob_thresh_1, nms_thresh_1, stardist_1_dir)\n",
    "        print('~~ Running predictions on channel 2 ~~')\n",
    "        do_stardist_prediction(model_2, T, 1, axes, prob_thresh_2, nms_thresh_2, stardist_2_dir)\n",
    "    else:\n",
    "        do_stardist_prediction(model, T, single_channel_to_segment-1, axes, prob_thresh_1, nms_thresh_1, stardist_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes from testing notebooks\n",
    "* Drift-corrected images haven't maintained pixel size metadata...\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69, 2, 600, 600)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python366\\lib\\site-packages\\dask\\dataframe\\utils.py:14: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Invalid dimensions for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-d1a4d80da79a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\python366\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, hold, data, **kwargs)\u001b[0m\n\u001b[0;32m   3203\u001b[0m                         \u001b[0mfilternorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3204\u001b[0m                         \u001b[0mimlim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3205\u001b[1;33m                         **kwargs)\n\u001b[0m\u001b[0;32m   3206\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3207\u001b[0m         \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python366\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1853\u001b[0m                         \u001b[1;34m\"the Matplotlib list!)\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1854\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[1;32m-> 1855\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1856\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1857\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[1;32mc:\\python366\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[0;32m   5485\u001b[0m                               resample=resample, **kwargs)\n\u001b[0;32m   5486\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5487\u001b[1;33m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5488\u001b[0m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5489\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python366\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36mset_data\u001b[1;34m(self, A)\u001b[0m\n\u001b[0;32m    651\u001b[0m         if not (self._A.ndim == 2\n\u001b[0;32m    652\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[1;32m--> 653\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid dimensions for image data\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    654\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    655\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Invalid dimensions for image data"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 252,
       "width": 262
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(T[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
